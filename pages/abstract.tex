\chapter{\abstractname}

%TODO: Abstract
Object extraction from images can be utilized for automatic decision-making tasks, such as autonomous driving. Recent deep learning models have shown great performance in this field, surpassing earlier methods in their accuracy. Typically, such models are trained using a large number of pixel-wise annotated images. However, obtaining pixel-wise annotations can be very costly and time-consuming. Moreover, training the models requires prior knowledge of all objects to be classified, which may not always be available. In this thesis, we explore the use of clustering methods to extract object descriptions and classification masks from feature images generated with pretrained image classification models. We propose passing an image through the feature extractor of a standard convolutional neural network to generate a context-aware feature representation of the image. Then, the pixel-wise feature vectors are clustered into coherent groups to obtain a segmentation mask of the image. The intuition is that the clusters will likely correspond to the different real-world objects found in the image due to the semantic information encoded in the cluster's members. Our experiments show that for semantically simple images that contain a small number of foreground objects, the segmentation results are stable and agree reasonably well with the human understanding of the objects in the image. More complex images, however, turn out to be difficult to segment with simple clustering algorithms due to the complexity and dimensionality of their feature representations. Future work can consider improving the segmentation of such images by addressing more elaborate clustering algorithms or using post-processing methods which can reduce the complexity of the feature representations.